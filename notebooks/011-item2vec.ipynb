{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33da6c3a-5942-4067-bd6c-0ff660efef2c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Training Skip Gram for Item2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea052f-fcc9-42cd-9ce6-d2241cd6100d",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6034ff-16b4-444e-8829-882d9a73662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0df0db9-14c5-40ec-a4a4-6631df59ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from typing import Any\n",
    "\n",
    "import lightning as L\n",
    "import mlflow\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel, PrivateAttr\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.id_mapper import IDMapper\n",
    "from src.skipgram.dataset import SkipGramDataset\n",
    "from src.skipgram.model import SkipGram\n",
    "from src.skipgram.trainer import LitSkipGram\n",
    "from src.skipgram.inference import SkipGramInferenceWrapper\n",
    "from src.viz import blueq_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c8734-972a-4dbc-8fef-c38f69613bcd",
   "metadata": {},
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13ebf4-0a42-4428-94d1-8c12bacc342e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "max_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d223693-130f-4261-acb4-0231febfad67",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:41:16.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mSetting up MLflow experiment FSDS RecSys - L7 - Model Serving - run 000-first-attempt...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"FSDS RecSys - L7 - Model Serving\",\n",
      "  \"run_name\": \"000-first-attempt\",\n",
      "  \"notebook_persist_dp\": \"/Users/quy.dinh/frostmourne/recsys-mvp/notebooks/data/000-first-attempt\",\n",
      "  \"random_seed\": 41,\n",
      "  \"device\": null,\n",
      "  \"max_epochs\": 1,\n",
      "  \"batch_size\": 128,\n",
      "  \"num_negative_samples\": 2,\n",
      "  \"window_size\": 1,\n",
      "  \"embedding_dim\": 128,\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"learning_rate\": 0.01,\n",
      "  \"l2_reg\": 0.00001,\n",
      "  \"mlf_model_name\": \"item2vec\",\n",
      "  \"min_roc_auc\": 0.7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    _mlf_logger: Any = PrivateAttr()\n",
    "    experiment_name: str = \"RecSys MVP\"\n",
    "    run_name: str = \"000-first-attempt\"\n",
    "    notebook_persist_dp: str = None\n",
    "    random_seed: int = 41\n",
    "    device: str = None\n",
    "\n",
    "    max_epochs: int = max_epochs\n",
    "    batch_size: int = 128\n",
    "\n",
    "    num_negative_samples: int = 2\n",
    "    window_size: int = 1\n",
    "\n",
    "    embedding_dim: int = 128\n",
    "    early_stopping_patience: int = 5\n",
    "    learning_rate: float = 0.01\n",
    "    l2_reg: float = 1e-5\n",
    "\n",
    "    mlf_model_name: str = \"item2vec\"\n",
    "    min_roc_auc: float = 0.7\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persist_dp = os.path.abspath(f\"data/{self.run_name}\")\n",
    "        os.makedirs(self.notebook_persist_dp, exist_ok=True)\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            logger.warning(\n",
    "                f\"Environment variable MLFLOW_TRACKING_URI is not set. Setting self.log_to_mlflow to false.\"\n",
    "            )\n",
    "            self.log_to_mlflow = False\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up MLflow experiment {self.experiment_name} - run {self.run_name}...\"\n",
    "            )\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88abb2f3-6564-4587-b3fc-fbfa2597ed1f",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ecd5df-f25a-42d5-800d-6fc67e616384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_items, embedding_dim):\n",
    "    model = SkipGram(n_items, embedding_dim)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa75d42e-6cbf-4355-ab2a-9628d1664bd6",
   "metadata": {},
   "source": [
    "# Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf57b8aa-d3b6-4066-9399-296f29fd138d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4960, 0.4963, 0.4978], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_items = 1000\n",
    "window_size = 1\n",
    "negative_samples = 2\n",
    "batch_size = 2\n",
    "\n",
    "model = init_model(n_items, args.embedding_dim)\n",
    "\n",
    "# Example inputs\n",
    "target_items = torch.tensor([1, 2, 3])  # Target item IDs\n",
    "context_items = torch.tensor([10, 20, 30])  # Context item IDs\n",
    "labels = torch.tensor([1, 0, 1])  # Positive or negative context pairs\n",
    "\n",
    "# Forward pass\n",
    "predictions = model(target_items, context_items)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "141c6044-5257-4b21-a9a5-d28098be5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:41:16.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.skipgram.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mProcessing sequences to build interaction data...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fd6cd7dafb4da7babfa9e2c6b7d6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building interactions: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mock dataset\n",
    "sequences = [\n",
    "    [\"b\", \"c\", \"d\", \"e\", \"a\"],\n",
    "    [\"f\", \"b\", \"k\"],\n",
    "    [\"g\", \"m\", \"k\", \"l\", \"h\"],\n",
    "    [\"b\", \"c\", \"k\"],\n",
    "    [\"j\", \"i\", \"c\"],\n",
    "]\n",
    "\n",
    "sequences_fp = \"sequences.jsonl\"\n",
    "\n",
    "with open(sequences_fp, \"w\") as f:\n",
    "    for sequence in sequences:\n",
    "        f.write(json.dumps(sequence) + \"\\n\")\n",
    "\n",
    "dataset = SkipGramDataset(\n",
    "    sequences_fp, window_size=window_size, negative_samples=negative_samples\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11931278-eab4-4ec4-9214-b5442cc21788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_items': tensor([0, 0, 0, 1, 1, 1, 1, 1, 1]), 'context_items': tensor([ 1,  9,  7,  0,  2,  9, 10,  7, 10]), 'labels': tensor([1., 0., 0., 1., 1., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc1b8761-6aa5-4ff4-9286-e02d9055fb33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type     | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | skipgram_model | SkipGram | 128 K  | train\n",
      "----------------------------------------------------\n",
      "128 K     Trainable params\n",
      "0         Non-trainable params\n",
      "128 K     Total params\n",
      "0.513     Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36550699e4347a88da4c19e9a3d8f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lit_model = LitSkipGram(model, log_dir=args.notebook_persist_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(default_root_dir=f\"{args.notebook_persist_dp}/test\", max_epochs=2)\n",
    "trainer.fit(\n",
    "    model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2f70f-798a-4aea-b1eb-2ec51ee02962",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe65737-8547-486e-97b1-6d2de9f95fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_fp = \"../data/item_sequence.jsonl\"\n",
    "val_sequences_fp = \"../data/val_item_sequence.jsonl\"\n",
    "idm = IDMapper().load(\"../data/idm.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed11ba0-0ce7-4cef-96c1-ab9ba564327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:41:17.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.skipgram.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mProcessing sequences to build interaction data...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c85dbdf8e404a40b5614f77e903734f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building interactions: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:41:18.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.skipgram.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mProcessing sequences to build interaction data...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7271a516bcb74e059ed7f0fc349e1e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building interactions: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = SkipGramDataset(\n",
    "    sequences_fp,\n",
    "    window_size=args.window_size,\n",
    "    negative_samples=args.num_negative_samples,\n",
    "    id_to_idx=idm.item_to_index,\n",
    ")\n",
    "val_dataset = SkipGramDataset(\n",
    "    val_sequences_fp,\n",
    "    dataset.interacted,\n",
    "    dataset.item_freq,\n",
    "    window_size=args.window_size,\n",
    "    negative_samples=args.num_negative_samples,\n",
    "    id_to_idx=idm.item_to_index,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    # TODO: Understand and make use of this parallel workers to make the model train faster\n",
    "    # num_workers=4,\n",
    "    # persistent_workers=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=val_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b52de7-e5fe-4d9e-93a2-511c97fe1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset.id_to_idx == idm.item_to_index, \"ID Mappings are not matched!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e569f67-6cd9-4d69-b06c-98de2b649ce0",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba12147-427e-43ac-b392-2c30a21feb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = len(dataset.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce01e4-4611-4195-b339-018b41a0576a",
   "metadata": {},
   "source": [
    "## Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d3006cc-5220-4984-b174-fe1910d522f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:41:18.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.skipgram.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mProcessing sequences to build interaction data...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efc1ba388b94b18a025ff72742ef378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building interactions: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#papermill_description=overfit-1-batch\n",
    "# Still need to load the small 1 batch sample due to negative sampling which would cause the overfit_batches of Lightning to give new data every epochs\n",
    "batch_sequences_fp = \"../data/batch_item_sequence.jsonl\"\n",
    "batch_size = 1\n",
    "window_size = 1\n",
    "num_negative_samples = 2\n",
    "\n",
    "batch_dataset = SkipGramDataset(\n",
    "    batch_sequences_fp, window_size=window_size, negative_samples=num_negative_samples\n",
    ")\n",
    "batch_train_loader = DataLoader(\n",
    "    batch_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe9232a-3c22-4499-8785-895bc02ab648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_items': tensor([0, 0, 0]), 'context_items': tensor([1, 7, 8]), 'labels': tensor([1., 0., 0.])}\n",
      "{'target_items': tensor([1, 1, 1, 1, 1, 1]), 'context_items': tensor([ 0,  2,  9,  8, 10,  9]), 'labels': tensor([1., 1., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch_input in batch_train_loader:\n",
    "    print(batch_input)\n",
    "    i += 1\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde31efe-ab35-427e-a7cf-1abc55368845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name           | Type     | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | skipgram_model | SkipGram | 1.5 K  | train\n",
      "----------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:251: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled val dataloader shuffling. We are turning off the val dataloader shuffling for you.\n",
      "\n",
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:251: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "\n",
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8651a3f6534fffae4edaf20aa87a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:41:18.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mLogs available at /Users/quy.dinh/frostmourne/recsys-mvp/notebooks/data/000-first-attempt/logs/overfit/lightning_logs/version_0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "# model\n",
    "model = init_model(len(batch_dataset.items), args.embedding_dim)\n",
    "lit_model = LitSkipGram(\n",
    "    model, learning_rate=0.01, l2_reg=0.0, log_dir=args.notebook_persist_dp\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=batch_train_loader,\n",
    "    val_dataloaders=batch_train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5286aa6e-e29a-4a24-b976-c3d11db5c0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-137ee319f016fbdd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-137ee319f016fbdd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $trainer.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af03779b-5a9a-4ad5-b88d-76b480397bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9820], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([0]), torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde36ee-3233-43ba-9d97-83aa95e3ffd5",
   "metadata": {},
   "source": [
    "## Run with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04a76ba-1532-4497-b7d4-c947afb1ecd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type     | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | skipgram_model | SkipGram | 592 K  | train\n",
      "----------------------------------------------------\n",
      "592 K     Trainable params\n",
      "0         Non-trainable params\n",
      "592 K     Total params\n",
      "2.371     Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n",
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbc85674f9d427dae6ec5305bec9a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "2024/10/10 11:42:16 INFO mlflow.tracking._tracking_service.client: üèÉ View run 000-first-attempt at: http://localhost:5002/#/experiments/1/runs/e72b532535be4763a191c6da5591040c.\n",
      "2024/10/10 11:42:16 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5002/#/experiments/1.\n",
      "\u001b[32m2024-10-10 11:42:16.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mLogs available at None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#papermill_description=fit-model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=args.early_stopping_patience, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persist_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# model\n",
    "model = init_model(n_items, args.embedding_dim)\n",
    "lit_model = LitSkipGram(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d82fee2-7f9a-41da-8da1-10d770fb1e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5856], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([0]), torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dcbefc-1108-4b0a-9945-0f60d710f5e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b5e02a-f717-4441-8f4e-2a9010a99218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_trainer = LitSkipGram.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    skipgram_model=init_model(n_items, args.embedding_dim),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c566f47-168b-4843-a255-958467c6bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_trainer.skipgram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5b942b4-8cf5-4b71-bb94-eee36525dc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0724, -0.0767, -0.2191, -0.0854,  0.1054], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.to(\"cpu\").embeddings(torch.tensor(0))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090686e-2692-4ddc-a60a-59d4195d148e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Persist id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49e34ade-2d7e-4aa1-a2f5-0425edcea658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:42:17.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mSaving id_mapping to /Users/quy.dinh/frostmourne/recsys-mvp/notebooks/data/000-first-attempt/skipgram_id_mapping.json...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Persist id_mapping so that at inference we can predict based on item_ids (string) instead of item_index\n",
    "id_mapping_filename = \"skipgram_id_mapping.json\"\n",
    "id_mapping_path = f\"{args.notebook_persist_dp}/{id_mapping_filename}\"\n",
    "logger.info(f\"Saving id_mapping to {id_mapping_path}...\")\n",
    "dataset.save_id_mappings(id_mapping_path)\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    mlf_client = trainer.logger.experiment\n",
    "    mlf_client.log_artifact(run_id, id_mapping_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be122362-ec87-4e08-bc95-6a240cf00133",
   "metadata": {},
   "source": [
    "### Wrap inference function and register best checkpoint as MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1711a1cb-59b8-4143-a968-66c0d1d1933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferrer = SkipGramInferenceWrapper(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4e010cf-4ab9-4011-9bd7-cf1849eefd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5856392], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input = {\"item_1_ids\": [dataset.idx_to_id[0]], \"item_2_ids\": [dataset.idx_to_id[1]]}\n",
    "sample_output = inferrer.infer([0], [1])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44428fb7-5228-40d1-8060-b5b1c9e64859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quy.dinh/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/mlflow/models/utils.py:523: FutureWarning:\n",
      "\n",
      "Since MLflow 2.16.0, we no longer convert dictionary input example to pandas Dataframe, and directly save it as a json object. If the model expects a pandas DataFrame input instead, please pass the pandas DataFrame as input example directly.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd79841c92444555a47300847718c1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'item2vec'.\n",
      "2024/10/10 11:42:20 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: item2vec, version 1\n",
      "Created version '1' of model 'item2vec'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddf6be26f374cd3947e0eccef106018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/10 11:42:21 INFO mlflow.tracking._tracking_service.client: üèÉ View run 000-first-attempt at: http://localhost:5002/#/experiments/1/runs/e72b532535be4763a191c6da5591040c.\n",
      "2024/10/10 11:42:21 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5002/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    sample_output_np = sample_output\n",
    "    signature = infer_signature(sample_input, sample_output_np)\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=inferrer,\n",
    "            artifact_path=\"inferrer\",\n",
    "            # We log the id_mapping to the predict function so that it can accept item_id and automatically convert ot item_indice for PyTorch model to use\n",
    "            artifacts={\"id_mapping\": mlflow.get_artifact_uri(id_mapping_filename)},\n",
    "            signature=signature,\n",
    "            input_example=sample_input,\n",
    "            registered_model_name=args.mlf_model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc9038-642a-4da3-8677-90ba8b8eb744",
   "metadata": {},
   "source": [
    "# Set the newly trained model as champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "132067bb-a945-428a-ad35-1239172fff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 11:42:21.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mAliasing the new model as champion...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if args.log_to_mlflow:\n",
    "    val_roc_auc = trainer.logger.experiment.get_run(trainer.logger.run_id).data.metrics[\n",
    "        \"val_roc_auc\"\n",
    "    ]\n",
    "\n",
    "    if val_roc_auc > args.min_roc_auc:\n",
    "        logger.info(f\"Aliasing the new model as champion...\")\n",
    "        model_version = (\n",
    "            mlf_client.get_registered_model(args.mlf_model_name)\n",
    "            .latest_versions[0]\n",
    "            .version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_registered_model_alias(\n",
    "            name=args.mlf_model_name, alias=\"champion\", version=model_version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_model_version_tag(\n",
    "            name=args.mlf_model_name,\n",
    "            version=model_version,\n",
    "            key=\"author\",\n",
    "            value=\"quy.dinh\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab72a17-f4b6-4ac9-a62e-014b83125af6",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8c6bc09-55e9-41e8-9890-1f53e22d7fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/10 11:42:26 INFO mlflow.tracking._tracking_service.client: üèÉ View run 000-first-attempt at: http://localhost:5002/#/experiments/1/runs/e72b532535be4763a191c6da5591040c.\n",
      "2024/10/10 11:42:26 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5002/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.dict()\n",
    "            params_ = {\n",
    "                f\"{params.__repr_name__()}.{k}\": v for k, v in params_dict.items()\n",
    "            }\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cc5dc-5337-49a2-aa2d-174ff0387c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
