{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf1577c-6f3b-4b1c-a848-8f5e45ff8111",
   "metadata": {},
   "source": [
    "# Sequence modeling for ranking task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309e017-0449-46ee-b7ca-4c4bcadeedf6",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8f6e8d-f776-4d39-898c-d783c5ae3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b3499d-dc9c-405a-8714-a26341b581e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.dataset import UserItemBinaryDFDataset as UserItemRatingDFDataset\n",
    "from src.id_mapper import IDMapper\n",
    "from src.sequence.inference import SequenceRatingPredictionInferenceWrapper\n",
    "from src.sequence.model import SequenceRatingPrediction\n",
    "from src.sequence.trainer import LitSequenceRatingPrediction\n",
    "from src.sequence.utils import generate_item_sequences\n",
    "from src.viz import blueq_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd804021-3424-48e0-973a-e662a72db544",
   "metadata": {},
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce522d9e-f35c-4cc5-a71e-68447956b31f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4e9a93-5b6a-4dec-97f0-b9aa3383c64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-26 13:51:57.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mSetting up MLflow experiment RecSys MVP - Sequence Modeling - run 002-try-binary...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"RecSys MVP - Sequence Modeling\",\n",
      "  \"run_name\": \"002-try-binary\",\n",
      "  \"notebook_persist_dp\": \"/Users/dvq/frostmourne/recsys-mvp/notebooks/data/002-try-binary\",\n",
      "  \"random_seed\": 41,\n",
      "  \"device\": null,\n",
      "  \"max_epochs\": 100,\n",
      "  \"batch_size\": 128,\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"embedding_dim\": 128,\n",
      "  \"dropout\": 0.3,\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 0.0001,\n",
      "  \"mlf_item2vec_model_name\": \"item2vec\",\n",
      "  \"mlf_model_name\": \"sequence_rating_prediction\",\n",
      "  \"min_roc_auc\": 0.7,\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"RecSys MVP - Sequence Modeling\"\n",
    "    run_name: str = \"002-try-binary\"\n",
    "    notebook_persist_dp: str = None\n",
    "    random_seed: int = 41\n",
    "    device: str = None\n",
    "\n",
    "    max_epochs: int = max_epochs\n",
    "    batch_size: int = 128\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 128\n",
    "\n",
    "    embedding_dim: int = 128\n",
    "    dropout: float = 0.3\n",
    "    early_stopping_patience: int = 5\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-4\n",
    "\n",
    "    mlf_item2vec_model_name: str = \"item2vec\"\n",
    "    mlf_model_name: str = \"sequence_rating_prediction\"\n",
    "    min_roc_auc: float = 0.7\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persist_dp = os.path.abspath(f\"data/{self.run_name}\")\n",
    "        os.makedirs(self.notebook_persist_dp, exist_ok=True)\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            logger.warning(\n",
    "                f\"Environment variable MLFLOW_TRACKING_URI is not set. Setting self.log_to_mlflow to false.\"\n",
    "            )\n",
    "            self.log_to_mlflow = False\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up MLflow experiment {self.experiment_name} - run {self.run_name}...\"\n",
    "            )\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acedcb-89e6-41c6-8969-bf3437fc7898",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a34cb5b-c7db-4b95-952b-5f4cb2e1a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_users, n_items, embedding_dim, dropout, item_embedding=None):\n",
    "    model = SequenceRatingPrediction(\n",
    "        n_users, n_items, embedding_dim, dropout=dropout, item_embedding=item_embedding\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b92fb-3b4c-482f-a584-62288873d8c3",
   "metadata": {},
   "source": [
    "## Load pretrained Item2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cfc84a-75bb-4973-b619-194cc8698ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5d132cd84d416e9fed34fbb7b1eccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlf_client = mlflow.MlflowClient()\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{args.mlf_item2vec_model_name}@champion\"\n",
    ")\n",
    "skipgram_model = model.unwrap_python_model().model\n",
    "embedding_0 = skipgram_model.embeddings(torch.tensor(0))\n",
    "embedding_dim = embedding_0.size()[0]\n",
    "id_mapping = model.unwrap_python_model().id_mapping\n",
    "pretrained_item_embedding = skipgram_model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3baa82d-859d-4414-8e19-4c7d92750fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    pretrained_item_embedding.embedding_dim == args.embedding_dim\n",
    "), \"Mismatch pretrained item_embedding dimension\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a71da-1ee3-474c-b3f4-4488d2a45dd3",
   "metadata": {},
   "source": [
    "# Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5326d7-ec9d-422c-bbd8-03c837a23e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4816]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 8\n",
    "batch_size = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 4, 5, 3, 0]\n",
    "item_sequences = [\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 1, 3],\n",
    "    [-1, -1, 2, 1],\n",
    "    [-1, -1, 2, 1],\n",
    "]\n",
    "\n",
    "n_users = len(set(user_indices))\n",
    "n_items = len(set(item_indices))\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "        \"item_sequence\": item_sequences,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, embedding_dim, args.dropout)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-1, -1, -1, 0, 1]])\n",
    "target_item = torch.tensor([2])\n",
    "predictions = model.predict(user, item_sequence, target_item)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0b1fea-0376-4624-ad8a-d000208a97f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(rating_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e82d3d1-826a-409b-8440-46e0bd924269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([0, 0]), 'item': tensor([0, 1]), 'rating': tensor([0., 1.]), 'item_sequence': tensor([[-1, -1,  2,  3],\n",
      "        [-1, -1,  2,  3]]), 'item_feature': tensor([], size=(2, 0))}\n",
      "{'user': tensor([1, 2]), 'item': tensor([2, 3]), 'rating': tensor([1., 1.]), 'item_sequence': tensor([[-1, -1,  1,  3],\n",
      "        [-1, -1,  2,  1]]), 'item_feature': tensor([], size=(2, 0))}\n",
      "{'user': tensor([2]), 'item': tensor([4]), 'rating': tensor([0.]), 'item_sequence': tensor([[-1, -1,  2,  1]]), 'item_feature': tensor([], size=(1, 0))}\n"
     ]
    }
   ],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02cb9ca4-11f1-45a8-911b-ed11c8391944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                     | Params | Mode\n",
      "----------------------------------------------------------\n",
      "0 | model | SequenceRatingPrediction | 729    | eval\n",
      "----------------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "11        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dvq/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
      "/Users/dvq/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
      "/Users/dvq/frostmourne/recsys-mvp/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2084341e71c40d9acee4a9dd5f0fce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "\u001b[32m2024-10-26 13:51:59.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lit_model = LitSequenceRatingPrediction(model, log_dir=args.notebook_persist_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=f\"{args.notebook_persist_dp}/test\",\n",
    "    max_epochs=2,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf019c8-db28-4538-91e8-3904b8800e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4548],\n",
      "        [0.4854],\n",
      "        [0.5073],\n",
      "        [0.3977]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "users = torch.tensor([0, 0, 0, 0])\n",
    "item_sequences = torch.tensor(\n",
    "    [[-1, -1, 2, 3], [-1, -1, 2, 3], [-1, -1, 1, 3], [-1, -1, 2, 1]]\n",
    ")\n",
    "items = torch.tensor([0, 1, 2, 3])\n",
    "predictions = model.predict(users, item_sequences, items)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f02734-1e63-4201-bd34-b3938ae50fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_indice  item_indice  timestamp   source  \\\n",
       "0            0           -1          4  predict   \n",
       "1            0           -1          4  predict   \n",
       "2            1           -1          4  predict   \n",
       "3            2           -1          4  predict   \n",
       "4            2           -1          4  predict   \n",
       "\n",
       "                             item_sequence  \n",
       "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]  \n",
       "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]  \n",
       "2  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2]  \n",
       "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]  \n",
       "4  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_predict_df(\n",
    "    train_df,\n",
    "    val_user_indices,\n",
    "    val_timestamp,\n",
    "    rating_col,\n",
    "    timestamp_col,\n",
    "    sequence_length=10,\n",
    "):\n",
    "    predict_df = pd.DataFrame(\n",
    "        {\n",
    "            \"user_indice\": val_user_indices,\n",
    "            \"item_indice\": -1,  # placeholder\n",
    "            \"timestamp\": val_timestamp,\n",
    "            \"source\": \"predict\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predict_df = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                train_df.loc[lambda df: df[rating_col].gt(0)][\n",
    "                    [\"user_indice\", \"item_indice\", timestamp_col]\n",
    "                ].assign(source=\"train\"),\n",
    "                predict_df,\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        .pipe(\n",
    "            generate_item_sequences,\n",
    "            \"user_indice\",\n",
    "            \"item_indice\",\n",
    "            timestamp_col,\n",
    "            sequence_length=sequence_length,\n",
    "            padding=True,\n",
    "            padding_value=-1,\n",
    "        )\n",
    "        .loc[lambda df: df[\"source\"].eq(\"predict\")]\n",
    "        .assign(item_sequence=lambda df: df[\"item_sequence\"].apply(np.array))\n",
    "    )\n",
    "\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "predict_df = create_predict_df(\n",
    "    train_df,\n",
    "    user_indices,\n",
    "    timestamps[-1],\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    sequence_length=10,\n",
    ")\n",
    "\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50fdcf97-6271-406d-81b5-7e91a4c42dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mq/xtxzhvlj4m97tb8lgwxcnsb40000gn/T/ipykernel_75946/349226613.py:3: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172dc616d35943ed9781608beccbd760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'user_indice': [0, 0, 0, 0, 1, 1, 2, 2, 2, 2],\n",
       " 'recommendation': [2, 1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
       " 'score': [0.4985326826572418,\n",
       "  0.4795783460140228,\n",
       "  0.4985326826572418,\n",
       "  0.4795783460140228,\n",
       "  0.5316905975341797,\n",
       "  0.5098885297775269,\n",
       "  0.563033401966095,\n",
       "  0.5588530898094177,\n",
       "  0.563033401966095,\n",
       "  0.5588530898094177]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = model.recommend(\n",
    "    torch.tensor(predict_df[\"user_indice\"].values),\n",
    "    torch.tensor(predict_df[\"item_sequence\"].values.tolist()),\n",
    "    k=2,\n",
    "    batch_size=4,\n",
    ")\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dec89-a874-4dce-8f94-07d978fcc5b8",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83803362-5eaa-40bb-b28b-878316d5db5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Mismatch IDM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m idm_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/idm.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m idm \u001b[38;5;241m=\u001b[39m IDMapper()\u001b[38;5;241m.\u001b[39mload(idm_fp)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (train_df[args\u001b[38;5;241m.\u001b[39muser_col]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m s: idm\u001b[38;5;241m.\u001b[39mget_user_index(s)) \u001b[38;5;241m!=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_indice\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch IDM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (val_df[args\u001b[38;5;241m.\u001b[39muser_col]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m s: idm\u001b[38;5;241m.\u001b[39mget_user_index(s)) \u001b[38;5;241m!=\u001b[39m val_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_indice\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch IDM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch IDM"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(\"../data/train_features_neg_df.parquet\")\n",
    "val_df = pd.read_parquet(\"../data/val_features_neg_df.parquet\")\n",
    "idm_fp = \"../data/idm.json\"\n",
    "idm = IDMapper().load(idm_fp)\n",
    "\n",
    "assert (\n",
    "    train_df[args.user_col].map(lambda s: idm.get_user_index(s))\n",
    "    != train_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "assert (\n",
    "    val_df[args.user_col].map(lambda s: idm.get_user_index(s)) != val_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1e6e9-48ba-4f48-b693-ac028845938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indices = train_df[\"user_indice\"].unique()\n",
    "item_indices = train_df[\"item_indice\"].unique()\n",
    "\n",
    "logger.info(f\"{len(user_indices)=:,.0f}, {len(item_indices)=:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a8ea7-928c-4656-b92c-2e137d78404a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260fbe7-2f90-44a1-be74-ce5db9b511ee",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a04ed-8898-443f-b0f4-7399bfa63810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "val_rating_dataset = UserItemRatingDFDataset(\n",
    "    val_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcf157-425f-4d15-9b53-e1ff93887def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, args.dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbb2a8-a578-4ad2-941e-efd01d930336",
   "metadata": {},
   "source": [
    "#### Predict before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d95ffc-0aec-4239-aa33-d75dc2f40b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.item_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0112de1e-1dce-4982-9663-a1df91fd0001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df = val_rating_dataset.df\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1583b-40f7-4157-a383-5891389ac119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_id = val_df.sample(1)[args.user_col].values[0]\n",
    "# user_id = \"AH4AOFTTDPHPAFAAVFMAF25H2LIQ\"\n",
    "test_df = val_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fbc80-eda8-4dff-a246-95f8f2f75082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_row = test_df.loc[lambda df: df[args.rating_col].gt(0)].iloc[0]\n",
    "item_id = test_row[args.item_col]\n",
    "item_sequence = test_row[\"item_sequence\"]\n",
    "logger.info(\n",
    "    f\"Test predicting before training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "user_indice = idm.get_user_index(user_id)\n",
    "item_indice = idm.get_item_index(item_id)\n",
    "user = torch.tensor([user_indice])\n",
    "item_sequence = torch.tensor([item_sequence])\n",
    "item = torch.tensor([item_indice])\n",
    "\n",
    "model.eval()\n",
    "model.predict(user, item_sequence, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd217c-c0c8-4e7c-81fe-6eb36f4729b5",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9daad4-1365-4e8e-8f73-80ca5513572b",
   "metadata": {},
   "source": [
    "##### Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cd9bd-e2c6-404b-b6ae-b26a7d35a0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, dropout=0)\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=0.0,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc9ae0-a993-4815-bebd-85cc51e68e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $trainer.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7e4af-5c66-454e-9e2c-2ca134f4e1cf",
   "metadata": {},
   "source": [
    "##### Fit on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef36c3-5263-4d91-8d7f-364d45c20719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# papermill_description=fit-model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=args.early_stopping_patience, mode=\"min\", verbose=False\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persist_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    dropout=args.dropout,\n",
    "    item_embedding=pretrained_item_embedding,\n",
    ")\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    evaluate_ranking=True,\n",
    "    idm=idm,\n",
    "    args=args,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44bf35-e7c7-4718-97b8-238e89b7f3f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    f\"Test predicting after training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "model.eval()\n",
    "model.predict(user, item_sequence, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1dd22-bcb9-4582-96d0-30acc4e8b790",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092427a8-ac4e-4752-a0ee-10729b6e563c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = LitSequenceRatingPrediction.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=init_model(n_users, n_items, args.embedding_dim, dropout=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68989e7-cd28-4cb3-9a28-5bd477bb67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_trainer.model.to(lit_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72062d94-6ee8-480f-b7c6-9dcae2ceeb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "best_model.predict(user, item_sequence, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afc39d-5cbd-4ea4-9484-f6419b460bde",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Persist id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bcb81-bf50-4757-9e63-5c7a317b276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Persist id_mapping so that at inference we can predict based on item_ids (string) instead of item_index\n",
    "    run_id = trainer.logger.run_id\n",
    "    mlf_client = trainer.logger.experiment\n",
    "    mlf_client.log_artifact(run_id, idm_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a53735-cada-4b16-b6ec-b958e20d8093",
   "metadata": {},
   "source": [
    "### Wrap inference function and register best checkpoint as MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1da4ca-1616-4f57-99fb-cb851c535a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferrer = SequenceRatingPredictionInferenceWrapper(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21791a9-d5fc-4abe-bc3c-820aba9f0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"user_ids\": [idm.get_user_id(0)],\n",
    "    \"item_sequences\": [[idm.get_item_id(0), idm.get_item_id(1)]],\n",
    "    \"item_ids\": [idm.get_item_id(0)],\n",
    "}\n",
    "sample_output = inferrer.infer([0], [[0, 1]], [0])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c043a-f777-4ade-ab80-cfa4d90aafa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    sample_output_np = sample_output\n",
    "    signature = infer_signature(sample_input, sample_output_np)\n",
    "    idm_filename = idm_fp.split(\"/\")[-1]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=inferrer,\n",
    "            artifact_path=\"inferrer\",\n",
    "            # We log the id_mapping to the predict function so that it can accept item_id and automatically convert ot item_indice for PyTorch model to use\n",
    "            artifacts={\"idm\": mlflow.get_artifact_uri(idm_filename)},\n",
    "            signature=signature,\n",
    "            input_example=sample_input,\n",
    "            registered_model_name=args.mlf_model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d5150-9851-4e61-b1af-8e619abc9ea4",
   "metadata": {},
   "source": [
    "# Set the newly trained model as champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6428a-bc47-400a-99ac-666abfa4ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    val_roc_auc = trainer.logger.experiment.get_run(trainer.logger.run_id).data.metrics[\n",
    "        \"val_roc_auc\"\n",
    "    ]\n",
    "\n",
    "    if val_roc_auc > args.min_roc_auc:\n",
    "        logger.info(f\"Aliasing the new model as champion...\")\n",
    "        model_version = (\n",
    "            mlf_client.get_registered_model(args.mlf_model_name)\n",
    "            .latest_versions[0]\n",
    "            .version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_registered_model_alias(\n",
    "            name=args.mlf_model_name, alias=\"champion\", version=model_version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_model_version_tag(\n",
    "            name=args.mlf_model_name,\n",
    "            version=model_version,\n",
    "            key=\"author\",\n",
    "            value=\"quy.dinh\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32096360-c26a-42de-9564-30634fb76eeb",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c6850-e4de-43fa-b132-0b97f138a0ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.dict()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cff81a-484e-4919-be8f-0351cce91a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
